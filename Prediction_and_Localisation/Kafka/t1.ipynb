{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ffmpeg was not found but is required to load audio files from filename",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\audio_utils.py:34\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[1;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mwith\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mPopen(ffmpeg_command, stdin\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE) \u001b[39mas\u001b[39;00m ffmpeg_process:\n\u001b[0;32m     35\u001b[0m         output_stream \u001b[39m=\u001b[39m ffmpeg_process\u001b[39m.\u001b[39mcommunicate(bpayload)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m transcribe \u001b[39m=\u001b[39m pipeline(task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mautomatic-speech-recognition\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvasista22/whisper-hindi-large-v2\u001b[39m\u001b[39m\"\u001b[39m, chunk_length_s\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m      9\u001b[0m transcribe\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mforced_decoder_ids \u001b[39m=\u001b[39m transcribe\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mget_decoder_prompt_ids(language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhi\u001b[39m\u001b[39m\"\u001b[39m, task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtranscribe\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTranscription: \u001b[39m\u001b[39m'\u001b[39m, transcribe(audio)[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:357\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    295\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    296\u001b[0m     inputs: Union[np\u001b[39m.\u001b[39mndarray, \u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m    297\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    298\u001b[0m ):\n\u001b[0;32m    299\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[39m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39m    documentation for more information.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\base.py:1132\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m   1133\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[0;32m   1134\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[0;32m   1135\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1136\u001b[0m             )\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m     )\n\u001b[0;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[0;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[0;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[0;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:183\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubiterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[39m# Try to return next item\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubiterator)\n\u001b[0;32m    184\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[39m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     \u001b[39m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[39m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[39m# into a single list, but with generators\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubiterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:434\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[1;34m(self, inputs, chunk_length_s, stride_length_s)\u001b[0m\n\u001b[0;32m    431\u001b[0m             inputs \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m--> 434\u001b[0m     inputs \u001b[39m=\u001b[39m ffmpeg_read(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor\u001b[39m.\u001b[39;49msampling_rate)\n\u001b[0;32m    436\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    437\u001b[0m extra \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\yolo\\Lib\\site-packages\\transformers\\pipelines\\audio_utils.py:37\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[1;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[0;32m     35\u001b[0m         output_stream \u001b[39m=\u001b[39m ffmpeg_process\u001b[39m.\u001b[39mcommunicate(bpayload)\n\u001b[0;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mffmpeg was not found but is required to load audio files from filename\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror\u001b[39;00m\n\u001b[0;32m     38\u001b[0m out_bytes \u001b[39m=\u001b[39m output_stream[\u001b[39m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m audio \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(out_bytes, np\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: ffmpeg was not found but is required to load audio files from filename"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# path to the audio file to be transcribed\n",
    "audio = \"209331024.wav\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transcribe = pipeline(task=\"automatic-speech-recognition\", model=\"vasista22/whisper-hindi-large-v2\", chunk_length_s=30, device=device)\n",
    "transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n",
    "\n",
    "print('Transcription: ', transcribe(audio)[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "class_colors = {0: \"green\", 63: \"red\"} #from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# base64_image = msg.value['captured_image']  # This is your base64 image from Kafka\n",
    "# main_res = msg.value['main_res']  # This is your main_res data from Kafka\n",
    "# result_base64 = draw_bounding_boxes(main_res, base64_image, color_classes)\n",
    " 0 for 'person', 63 for 'laptop'\n",
    "# base64_image = msg.value['captured_image']  # This is your base64 image from Kafka\n",
    "# main_res = msg.value['main_res']  # This is your main_res data from Kafka\n",
    "# result_base64 = draw_bounding_boxes(main_res, base64_image, class_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from your_mongo_helper_module import MongoHelper  # Replace with actual import\n",
    "\n",
    "# Assuming you have the variables camera_serial, main_res, path, and predictions_classes already set\n",
    "\n",
    "# Corrected message dictionary\n",
    "message = {\n",
    "    'camera_serial': camera_serial,\n",
    "    'main_res': main_res,\n",
    "    'captured_image': path,\n",
    "    'prediction_classes': predictions_classes,  # Corrected syntax\n",
    "    'is_rejected': True,\n",
    "    'date_time': datetime.now()  # Gets the current date and time\n",
    "}\n",
    "\n",
    "# Get the collection from MongoDB\n",
    "# Assuming _id is already set from the payload\n",
    "collection_name = \"inspection_\" + str(_id)\n",
    "mp = MongoHelper().getCollection(collection_name)\n",
    "\n",
    "# Insert the message into the collection\n",
    "mp.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime(\"%Y%m%d\")  # Corrected datetime usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240304'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = datetime.now().strftime(\"%d-%m-%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04-03-2024'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MongoHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_helper = MongoHelper()\n",
    "db = mongo_helper.getDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'acym'), '1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_collection('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "drawin_img = np.zeros((512, 512, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drawin_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw ,ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('65e568989d54f115a3dafb76'), acknowledged=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_id = ObjectId()  # Generate a unique object ID for image naming\n",
    "img_path = f\"images/{img_id}.jpg\"\n",
    "Image.fromarray(drawin_img).save(img_path)\n",
    "today =datetime.now().strftime(\"%d-%m-%Y\")\n",
    "current_time = datetime.now()\n",
    "# Format the time to display only hours, minutes, and seconds\n",
    "formatted_time = current_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "running_part_collection = mongo_helper.getCollection('running_part')\n",
    "\n",
    "# Fetch the running part name\n",
    "part_name = running_part_collection.find_one({}, {'part_name': 1})\n",
    "print(part_name)\n",
    "if part_name != None:\n",
    "    pt_name = part_name['part_name']\n",
    "print(pt_name)\n",
    "\n",
    "\n",
    "\n",
    "collection_name = f\"{today}_g\" \n",
    "message_db = {\n",
    "    \"img_path\": 'img_path',\n",
    "    \"accepts\": {\n",
    "        'ct_dict':1\n",
    "    },\n",
    "    \"part_name\":pt_name,\n",
    "    'time': 'formatted_time'\n",
    "}\n",
    "\n",
    "collection = mongo_helper.getCollection(collection_name)\n",
    "collection.insert_one(message_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection to (192.168.1.10, 502) failed: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to connect to Modbus Server\n"
     ]
    }
   ],
   "source": [
    "from pymodbus.client import ModbusTcpClient as ModbusClient\n",
    "\n",
    "# Configuration\n",
    "IP_ADDRESS = '192.168.1.10'\n",
    "PORT = 502  # Default Modbus TCP port\n",
    "\n",
    "# Connect to the Modbus server\n",
    "client = ModbusClient(IP_ADDRESS, port=PORT)\n",
    "connection = client.connect()\n",
    "\n",
    "if connection:\n",
    "    print(\"Connected to Modbus Server\")\n",
    "    \n",
    "    # Writing 1 to registers 8802, 8803, 8804, and 8805\n",
    "    write_registers = [1, 1, 1, 1]\n",
    "    address = 8802  # Starting address\n",
    "    response = client.write_registers(address, write_registers)\n",
    "    \n",
    "    if response.isError():\n",
    "        print(\"Error writing registers:\", response)\n",
    "    else:\n",
    "        print(\"Successfully wrote 1 to registers 8802, 8803, 8804, and 8805\")\n",
    "else:\n",
    "    print(\"Failed to connect to Modbus Server\")\n",
    "\n",
    "# Close the connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "import pymodbus.client as ModbusClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection to (192.168.1.10, 502) failed: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLC Connection Failed.\n"
     ]
    }
   ],
   "source": [
    "from pymodbus.client import ModbusTcpClient\n",
    "\n",
    "# Replace with your PLC's actual IP address\n",
    "PLC_IP = \"192.168.1.10\"\n",
    "\n",
    "# Standard Modbus TCP port\n",
    "PORT = 502 \n",
    "\n",
    "def check_plc_connection():\n",
    "    client = ModbusTcpClient(PLC_IP, port=PORT)\n",
    "\n",
    "    try:\n",
    "        connection_result = client.connect()\n",
    "        if connection_result:\n",
    "            print(\"PLC Connection Successful!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"PLC Connection Failed.\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Connection Error:\", e)\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_plc_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
